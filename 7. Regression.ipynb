{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada58c94-0e87-49dc-ab8e-a58d40838371",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150f8e8-8c77-441a-8ab2-f560390eb891",
   "metadata": {},
   "source": [
    "Just like classification, we will use previous data to predict future observations. However, instead of predicting cateogrical variables, we will be predicting numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ed2b2-878a-4c6f-ad20-f2d50386ac07",
   "metadata": {},
   "source": [
    "## Regression with $K$-nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d720c-ad2e-4fde-b02c-7b0241caaf1f",
   "metadata": {},
   "source": [
    "```slice_sample(dataset, n = some_number)``` - takes a small random sample from a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b482d4d7-5409-4658-b545-528f644dbac2",
   "metadata": {},
   "source": [
    "***Let's say we want to predict the price of a house that is 2000 square feet large.***\n",
    "\n",
    "<img src=\"media/2000_square_feet_house.png\" width=\"300px\">\n",
    "\n",
    "We will use the neighboring points to the find the new point of interest to suggest/predict what the sales price might be.\n",
    "\n",
    "```r\n",
    "sacramento <- read_csv(...)\n",
    "small_sacramento <- slice_sample(sacramento, n = 30)\n",
    "\n",
    "nearest_neighbors <- small_sacramento %>%\n",
    "                     mutate(diff = abs(2000 - sqft)) %>%\n",
    "                     arrange(diff) %>%\n",
    "                     slice(1:5) # subset the first 5 rows\n",
    "```\n",
    "\n",
    "<img src=\"media/nearest_neighbors.png\" width=\"400px\">\n",
    "\n",
    "Then we can predict the mean of the nearest neighbors.\n",
    "\n",
    "```r\n",
    "prediction <- nearest_neighbors %>%\n",
    "              summarise(predicted = mean(price))\n",
    "\n",
    "prediction\n",
    "\n",
    "> 326324\n",
    "```\n",
    "\n",
    "<img src=\"media/regression_prediction.png\" width=\"300px\">\n",
    "\n",
    "***NOTE: The best part about KNN regression is that it also works well with non-linear relationships because the algorithm has very few assumptions about what the data must look like.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322d541-e52e-49d2-967b-73c766b9044d",
   "metadata": {},
   "source": [
    "### Training, evaluating and tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07660db-518d-4cc1-809d-54064e8850ce",
   "metadata": {},
   "source": [
    "In KNN classification, we used accuracy to see how our predictions matched the true labels. In KNN regression, we will use root mean square prediction error (RMSPE) instead because our predictions will never match the true response variable values.\n",
    "\n",
    "***NOTE:***\n",
    "- When predicting and evaluating the prediction quality on the ***TRAINING DATA*** we say $RMSE$.\n",
    "    - measures how well the model predicts on data it was trained with.\n",
    "- When predicting and evaluating the prediction quality on the ***TESTING DATA*** we say $RMSPE$.\n",
    "    - measures the prediction quality (predicts on data it was not trained with)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f0495-4286-45fd-9cc0-f9a5bf39b4d8",
   "metadata": {},
   "source": [
    "$ RMSPE = \\sqrt{\\frac{1}{n} \\sum_{i = 1} ^ n (y_i - \\hat{y}_i)^2} $\n",
    "\n",
    "Where:\n",
    "- $n$ is the number of observations\n",
    "- $y_i$ is the observed value for the $i^th$ observation\n",
    "- $\\hat{y}_i$ is the forecasted/predicted value for the $i^th$ observation\n",
    "\n",
    "<img src=\"media/rmspe.png\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316f954-abb8-4359-90b6-ac0bd6331c98",
   "metadata": {},
   "source": [
    "#### Finding the Optimal $K$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706cea5-bfb9-4b35-ba44-0258323c5e84",
   "metadata": {},
   "source": [
    "```r\n",
    "some_recipe <- recipe(label ~ predictors, data = dataset_training) %>%\n",
    "               step_scale(all_predictors()) %>%\n",
    "               step_center(all_predictors())\n",
    "               \n",
    "some_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "             set_engine(\"kknn\") %>%\n",
    "             set_mode(\"regression\")\n",
    "\n",
    "some_vfold <- vfold_cv(dataset_training, v = 5, strata = label)\n",
    "\n",
    "some_workflow <- workflow() %>%\n",
    "                 add_recipe(some_recipe) %>%\n",
    "                 add_model(some_spec)\n",
    "\n",
    "gridvals <- tibble(neighbors = seq(from = 1, to = 200, by = 3))\n",
    "\n",
    "some_results <- some_workflow %>%\n",
    "                tune_grid(resamples = some_vfold, grid = gridvals) %>%\n",
    "                collect_metrics() %>%\n",
    "                filter(.metric == \"rmse\")\n",
    "```\n",
    "\n",
    "<img src=\"media/optimal_k_regression.png\" width=\"400px\">\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab0ce2-00cb-400d-86ff-5e6675452249",
   "metadata": {},
   "source": [
    "To find the most optimal number of neighbors $K$, we take the ***minimum*** RMSPE.\n",
    "\n",
    "```r\n",
    "some_min <- some_resuts %>%\n",
    "            filter(mean == min(mean)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e889b6e8-421d-4391-800c-acc45517aa42",
   "metadata": {},
   "source": [
    "### Evaluating on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4b6bb-2c1c-454a-af35-efe3978e88d1",
   "metadata": {},
   "source": [
    "```r\n",
    "kmin <- some_min %>% pull(neighbors)\n",
    "\n",
    "some_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = kmin) |>\n",
    "             set_engine(\"kknn\") |>\n",
    "             set_mode(\"regression\")\n",
    "\n",
    "some_fit <- workflow() |>\n",
    "            add_recipe(some_recipe) |>\n",
    "            add_model(some_spec) |>\n",
    "            fit(data = some_training)\n",
    "\n",
    "some_summary <- some_fit |>\n",
    "                predict(some_test) |>\n",
    "                bind_cols(some_test) |>\n",
    "                metrics(truth = label, estimate = .pred) |>\n",
    "                filter(.metric == 'rmse')\n",
    "```\n",
    "\n",
    "<img src=\"media/evaluating_on_test_set.png\" width=\"400px\">\n",
    "\n",
    "Our final model's test error assessed by RMPSPE is $89279."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd38ffd-5233-4574-9b42-5ae9e824e96b",
   "metadata": {},
   "source": [
    "To show the predictions that our final model makes across the range of houses:\n",
    "\n",
    "```r\n",
    "some_preds <- tibble(sqft = seq(from = 500, to = 5000, by = 10))\n",
    "\n",
    "some_preds <- some_fit %>%\n",
    "              predict(some_preds) %>%\n",
    "              bind_cols(some_preds)\n",
    "\n",
    "plot_final <- ggplot(some_train, aes(x = car1, y = var2)) +\n",
    "                  geom_point(alpha = 0.4) +\n",
    "                  geom_line(data = some_preds, \n",
    "                            mapping = aes(x = var1, y = .pred), \n",
    "                            color = \"blue\") +\n",
    "                  xlab(\"House size (square feet)\") +\n",
    "                  ylab(\"Price (USD)\") +\n",
    "                  scale_y_continuous(labels = dollar_format()) +\n",
    "                  ggtitle(paste0(\"K = \", kmin)) + \n",
    "                  theme(text = element_text(size = 12))\n",
    "```\n",
    "***NOTE THE ```geom_line```***\n",
    "\n",
    "<img src=\"media/final_model_plot.png\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a13338-fc7f-4225-b639-93cfa03f52c5",
   "metadata": {},
   "source": [
    "### Multivariable KNN Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0198abf8-9a48-43d0-baf7-43927989a4ca",
   "metadata": {},
   "source": [
    "We can use the predictor selection algorithm from classification to select the best predictors in this case too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97255e73-e529-4cc3-8cb5-9051032f25db",
   "metadata": {},
   "source": [
    "First we'll build a new model specification and recipe for the analysis.\n",
    "\n",
    "```r\n",
    "some_recipe <- recipe(label ~ predictors, data = some_train) |>\n",
    "               step_scale(all_predictors()) |>\n",
    "               step_center(all_predictors())\n",
    "\n",
    "some_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "             set_engine(\"kknn\") |>\n",
    "             set_mode(\"regression\")\n",
    "```\n",
    "\n",
    "Next, we'll use 5-fold cross-validation to choose the number of neighbors vai the minimum RMSPE:\n",
    "\n",
    "```r\n",
    "gridvals <- tibble(neighbors = seq(1, 200))\n",
    "\n",
    "some_workflow <- workflow() |>\n",
    "                 add_recipe(some_recipe) |>\n",
    "                 add_model(some_spec) |>\n",
    "                 tune_grid(some_vfold, grid = gridvals) |>\n",
    "                 collect_metrics() |>\n",
    "                 filter(.metric == \"rmse\") |>\n",
    "                 filter(mean == min(mean))\n",
    "\n",
    "some_k <- some_workflow |> pull(neighbors)\n",
    "```\n",
    "\n",
    "Then, we need to re-train the model on the entire training data set.\n",
    "\n",
    "```r\n",
    "some_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = some_k) |>\n",
    "             set_engine(\"kknn\") |>\n",
    "             set_mode(\"regression\")\n",
    "\n",
    "knn_fit <- workflow() |>\n",
    "           add_recipe(some_recipe) |>\n",
    "           add_model(some_spec) |>\n",
    "           fit(data = some_train)\n",
    "\n",
    "knn_preds <- knn_fit |>\n",
    "             predict(some_test) |>\n",
    "             bind_cols(some_test)\n",
    "\n",
    "knn_mets <- metrics(knn_preds, truth = label, estimate = .pred) %>%\n",
    "            filter(.metric == 'rmse')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314643e3-355f-4fc9-a7d5-ca6d339ab56d",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d95d71-1c55-4092-b66b-aa686ab2ba29",
   "metadata": {},
   "source": [
    "**Strengths**: $K$-nearest neighbors regression:\n",
    "1. is a simple, intuitive algorithm\n",
    "2. requires few assumptions about what the data must look like\n",
    "3. works well with non-linear relationships (i.e., if the relationship is not a straight line).\n",
    "\n",
    "**Weaknesses**: $K$-nearest neighbors regression:\n",
    "1. becomes very slow as the training data gets larger\n",
    "2. may not perform well with a large number of predictors\n",
    "3. may not predict well beyond the range of values input in your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1c789-aff6-4363-a715-c91ce5b8c162",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1827ac-33a5-40c3-a5fa-ba72dd0f4764",
   "metadata": {},
   "source": [
    "Again, with the house price example, if we wanted to predict the price (USD) of a house that is 2000 square feet:\n",
    "\n",
    "$house \\space sale \\space price = \\beta_0 + \\beta_1 \\times (house \\space size)$\n",
    "\n",
    "where:\n",
    "- $\\beta_0$ is the vertical intercept of the line (the price when house size is 0)\n",
    "- $\\beta_1$ is the slope fo the line (how quickly the price increases as you increase house size)\n",
    "\n",
    "<img src=\"media/linear_regression_house_price.png\" width=\"300px\">\n",
    "\n",
    "Simple linear regression chooses the stright line of best fit by choosing the line that minimizes the **average squared vertical distance** between itself and each of the observed data points in training data.\n",
    "\n",
    "<img src=\"media/linear_regression_choosing_line.png\" width=\"300px\">\n",
    "\n",
    "Finally, to assess the predictive accuracy of the observed data points, we use RMSPE.\n",
    "\n",
    "***NOTE: RMSPE is the RMSE of the TEST DATA.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be40a8-88c6-4473-a4b5-b2ce28b62927",
   "metadata": {},
   "source": [
    "### Performing Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a953d-3296-481b-8aa6-aad86b3d2ce4",
   "metadata": {},
   "source": [
    "Load the library functions, get the data and split the data.\n",
    "\n",
    "```r\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "set.seed(1234)\n",
    "\n",
    "sacramento <- read_csv(\"data/sacramento.csv\")\n",
    "\n",
    "sacramento_split <- initial_split(sacramento, prop = 0.6, strata = price)\n",
    "sacramento_train <- training(sacramento_split)\n",
    "sacramento_test <- testing(sacramento_split)\n",
    "```\n",
    "\n",
    "Then we create model specifications, recipe, and workflow.\n",
    "\n",
    "```r\n",
    "lm_spec <- linear_reg() |>\n",
    "           set_engine(\"lm\") |>\n",
    "           set_mode(\"regression\")\n",
    "\n",
    "lm_recipe <- recipe(price ~ sqft, data = sacramento_train)\n",
    "\n",
    "lm_fit <- workflow() |>\n",
    "          add_recipe(lm_recipe) |>\n",
    "          add_model(lm_spec) |>\n",
    "          fit(data = sacramento_train)\n",
    "```\n",
    "\n",
    "***NOTE: We do not standardize our predictors! In leinear regression, standardization does not affect the fit (it does effective the coefficients in the equation)***\n",
    "\n",
    "<img src=\"media/fit_linear_regression.png\" width=\"400px;\">\n",
    "\n",
    "Our coefficients are (intercept) $\\beta_0 = 12292$ and (slope) $\\beta_1 = 140$. This means that the equation of best fit is:\n",
    "\n",
    "$house \\space sale \\space price = 12292 + 140 \\times (house \\space size)$\n",
    "\n",
    "Next, we predict on the test data to assess how well our model does:\n",
    "\n",
    "```r\n",
    "lm_test_results <- lm_fit |>\n",
    "                   predict(sacramento_test) |>\n",
    "                   bind_cols(sacramento_test) |>\n",
    "                   metrics(truth = price, estimate = .pred)\n",
    "```\n",
    "\n",
    "<img src=\"media/model_test_error_linear_regression.png\" width=\"400px\">\n",
    "\n",
    "Our final model's test error as assessed by RMSPE is 82,342 (remember that this is in units of the target/response variable, in this case USD).\n",
    "\n",
    "Next, we can plot our linear regression line using ```geom_smooth```:\n",
    "\n",
    "```r\n",
    "lm_plot_final <- ggplot(sacramento_train, aes(x = sqft, y = price)) +\n",
    "                     geom_point(alpha = 0.4) +\n",
    "                     xlab(\"House size (square feet)\") +\n",
    "                     ylab(\"Price (USD)\") +\n",
    "                     scale_y_continuous(labels = dollar_format()) +\n",
    "                     geom_smooth(method = \"lm\", se = FALSE) + \n",
    "                     theme(text = element_text(size = 12))\n",
    "```\n",
    "\n",
    "<img src=\"media/lm_plot_final.png\" width=\"300px\">\n",
    "\n",
    "\n",
    "We can, then, extract the coefficients from our model by accesssing the fit object that is output. We apply the ```tidy``` function to convert the result into a dataframe:\n",
    "\n",
    "```r\n",
    "coeffs <- lm_fit |>\n",
    "          pull_workflow_fit() |>\n",
    "          tidy()\n",
    "```\n",
    "\n",
    "<img src=\"media/linear_reg_coeff.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb365e42-bb28-4aad-bc3a-59cdf593bb82",
   "metadata": {},
   "source": [
    "### Comparing Linear Regression with KNN Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0d4475-46bb-40c1-a388-ff464817d8d7",
   "metadata": {},
   "source": [
    "<img src=\"media/lin_reg_vs_knn.png\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd56cc-46db-48fb-a9d4-734a4359404d",
   "metadata": {},
   "source": [
    "There is a major interprebility advantage in limiitng the model to the straight line. However, there are disadvantages, particularly when the relationship between the target and predictor is NOT linear but some other shape. In these cases the predcition model from LinReg would underfit (have high bias) meaning that model/predicted values do not match the actual observed values well.\n",
    "\n",
    "**Extrapolation**: Predicting outside the range of the observed data.\n",
    "\n",
    "Note that KNN regression becomes \"flat\" at the left and right boundaries of the data, while the linear model predicts a constant slope. Depending on the application, the flat or constant slope trend may make more sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d1076-6b86-456c-b632-d18c088f8c29",
   "metadata": {},
   "source": [
    "### Multivariable Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc05f7d-b7a1-461b-9f6a-ddd7da97614b",
   "metadata": {},
   "source": [
    "Like KNN regression, we just add more predictors to the model; however, we do not need to use cross-validation to choose any parameters, nor do we need to standardize (i.e., center and scale) the data for linear regression.\n",
    "\n",
    "```r\n",
    "mlm_recipe <- recipe(price ~ sqft + beds, data = sacramento_train)\n",
    "\n",
    "mlm_fit <- workflow() |>\n",
    "           add_recipe(mlm_recipe) |>\n",
    "           add_model(lm_spec) |>\n",
    "           fit(data = sacramento_train)\n",
    "\n",
    "lm_mult_test_results <- mlm_fit |>\n",
    "                        predict(sacramento_test) |>\n",
    "                        bind_cols(sacramento_test) |>\n",
    "                        metrics(truth = price, estimate = .pred)\n",
    "\n",
    "mcoeffs <- mlm_fit |>\n",
    "           pull_workflow_fit() |>\n",
    "           tidy()\n",
    "```\n",
    "\n",
    "<img src=\"media/multi_coefficients.png\" width=\"400px\">\n",
    "<img src=\"media/multi_test_results.png\" width=\"400px\">\n",
    "\n",
    "And then we can use the coefficiencts to write a mathematical equation to descrbe the prediction plane:\n",
    "\n",
    "$house \\space sale \\space price = \\beta_0 + \\beta_1 \\times (house \\space size) + \\beta_2 \\times (number \\space of \\space bedrooms)$\n",
    "\n",
    "In this case:\n",
    "\n",
    "$house \\space sale \\space price = 63475 + 166 \\times (house \\space size) - 28761 \\times (number \\space of \\space bedrooms)$\n",
    "\n",
    "And reading the predictor error, we find that our RMSPE is 81,417.89"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c8dd0-f2c0-44dd-be65-95864abd8453",
   "metadata": {},
   "source": [
    "### Multicollinearity and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dac7c3d-86e2-4999-8c9a-7c689ff03bfb",
   "metadata": {},
   "source": [
    "There are two common issues with linear regression: **1. Outliers** and **2. Collinear Predictors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffbcc5b-c199-4ee3-9a93-4ec8c2cca938",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114bdcc6-0ac8-4df0-89b2-54b05ef7bf27",
   "metadata": {},
   "source": [
    "Outliers can have too much influnce on the line of best fit. For instance, given our previous graph, adding one single oultier (red dot) can cause the line to shift tremendously:\n",
    "\n",
    "<img src=\"media/lin_reg_outliers.png\" width=\"300px\">\n",
    "\n",
    "This can be fixed with enough data. As long as you have enough data, the inlcusion of one or two outliers will typically not have a large effect on the line of best fit.\n",
    "\n",
    "<img src=\"media/lin_reg_outliers_lots_data.png\" width=\"300px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cbba26-6c81-4a11-9819-7034eca688dc",
   "metadata": {},
   "source": [
    "#### Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4d80c-11ea-413c-a1a1-51ac2bf7758e",
   "metadata": {},
   "source": [
    "If you include multiple predictors that are strongly linearly related to one another, the coefficients that are described in the plane of best fit can be very unreliable. Small changes to the data can result in large change in the coefficients.\n",
    "\n",
    "<img src=\"media/multicollinearity.png\" width=\"300px\">\n",
    "\n",
    "If we fit the multivariable inear regression model on this data, then the plane of best fit has regresion coefficients that are very sensitive to the exact values in the data.\n",
    "\n",
    "Best Fit 1: $house \\space sale \\space price = 3682 + (-43) \\times (house \\space size \\space 1 \\space (ft^2)) + (182) \\times (house \\space size \\space 2 \\space (ft^2))$ <br>\n",
    "Best Fit 2: $house \\space sale \\space price = 20596 + (312) \\times (house \\space size \\space 1 \\space (ft^2)) + (-172) \\times (house \\space size \\space 2 \\space (ft^2))$ <br>\n",
    "Best Fit 3: $house \\space sale \\space price = 6673 + (37) \\times (house \\space size \\space 1 \\space (ft^2)) + (104) \\times (house \\space size \\space 2 \\space (ft^2))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22205141-b8dd-430e-b08b-346b73b82445",
   "metadata": {},
   "source": [
    "### Designing New Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94830c00-96bf-4262-9094-f3cd91f62f16",
   "metadata": {},
   "source": [
    "Sometimes our predictor variable will not have a nearly linear relationship with our response variable. In cases like these, the only option is to obtain measurements of more useful variables. We can do this by scaling the variables.\n",
    "\n",
    "<img src=\"media/nonlinear_relationship_predictors.png\" width=\"300px\">\n",
    "\n",
    "We can create a new predictor variable by scaling the previous ones:\n",
    "\n",
    "```r\n",
    "df <- df %>%\n",
    "      mutate(z = x^3)\n",
    "```\n",
    "\n",
    "<img src=\"media/new_predictors.png\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218beb6-53bc-4e66-a6f6-f16f46954367",
   "metadata": {},
   "source": [
    "## GGPairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca02903-041b-40a2-b882-aaca3d3434b3",
   "metadata": {},
   "source": [
    "Creates scatterplot of all the columns we are interested in including our model.\n",
    "\n",
    "```r\n",
    "credit_eda <- credit_training %>%\n",
    "              ggpairs(columns = 1:3)\n",
    "```\n",
    "\n",
    "<img src=\"media/ggpairs.png\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd66323-a819-4f9a-9e6d-3162cd361b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
